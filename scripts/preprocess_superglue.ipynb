{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_multirc(in_path, out_path, split):\n",
    "    lines = []\n",
    "    passages, questions, answers, labels = [], [], [], []\n",
    "    with open(os.path.join(in_path, split+'.jsonl'), 'r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            lines.append(json.loads(line))\n",
    "    for line in lines:\n",
    "        passage = line[\"passage\"][\"text\"]\n",
    "        for question_dict in line[\"passage\"][\"questions\"]:\n",
    "            question = question_dict[\"question\"]\n",
    "            for answer_dict in question_dict[\"answers\"]:\n",
    "                answer = answer_dict[\"text\"]\n",
    "                passages.append(passage)\n",
    "                questions.append(question)\n",
    "                answers.append(answer)\n",
    "                labels.append(answer_dict['label'])     \n",
    "    if split == 'val':\n",
    "        split = 'valid' \n",
    "    with open(os.path.join(out_path, 'input0', split), 'w', encoding='utf-8') as f:\n",
    "        for l in passages:\n",
    "            f.write(l+'\\n')\n",
    "    with open(os.path.join(out_path, 'input1', split), 'w', encoding='utf-8') as f:\n",
    "        for l in questions:\n",
    "            f.write(l+'\\n')\n",
    "    with open(os.path.join(out_path, 'input2', split), 'w', encoding='utf-8') as f:\n",
    "        for l in answers:\n",
    "            f.write(l+'\\n')\n",
    "    with open(os.path.join(out_path, 'label', split), 'w', encoding='utf-8') as f:\n",
    "        for l in labels:\n",
    "            f.write(str(l)+'\\n')\n",
    "        \n",
    "root_path = '../../transformer/datasets/superglue/MultiRC/'\n",
    "output_path = os.path.join(root_path, 'processed')\n",
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)\n",
    "    os.mkdir(output_path+'/input0')\n",
    "    os.mkdir(output_path+'/input1')\n",
    "    os.mkdir(output_path+'/input2')\n",
    "    os.mkdir(output_path+'/label')\n",
    "preprocess_multirc(root_path, output_path, 'train')\n",
    "preprocess_multirc(root_path, output_path, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def preprocess_cb(in_path, out_path, split):\n",
    "    lines = []\n",
    "    ps, hs, labels = [], [], []\n",
    "    with open(os.path.join(in_path, split+'.jsonl'), 'r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            lines.append(json.loads(line))\n",
    "    for line in lines:\n",
    "        ps.append(line[\"premise\"])\n",
    "        hs.append(line[\"hypothesis\"])\n",
    "        labels.append(line[\"label\"])\n",
    "         \n",
    "    if split == 'val':\n",
    "        split = 'valid' \n",
    "    with open(os.path.join(out_path, 'input0', split), 'w', encoding='utf-8') as f:\n",
    "        for l in ps:\n",
    "            f.write(l+'\\n')\n",
    "    with open(os.path.join(out_path, 'input1', split), 'w', encoding='utf-8') as f:\n",
    "        for l in hs:\n",
    "            f.write(l+'\\n')\n",
    "    with open(os.path.join(out_path, 'label', split), 'w', encoding='utf-8') as f:\n",
    "        for l in labels:\n",
    "            f.write(str(l)+'\\n')\n",
    "    if split == 'train':\n",
    "        with open(os.path.join(out_path, 'label', 'dict.txt'), 'w', encoding='utf-8') as f:\n",
    "            label_dict = Counter(labels)\n",
    "            for k, v in label_dict.items():\n",
    "                f.write(k+\" \"+str(v))\n",
    "                f.write('\\n')\n",
    "root_path = '../../transformer/datasets/superglue/CB/'\n",
    "output_path = os.path.join(root_path, 'processed')\n",
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)\n",
    "    os.mkdir(output_path+'/input0')\n",
    "    os.mkdir(output_path+'/input1')\n",
    "    os.mkdir(output_path+'/label')\n",
    "preprocess_cb(root_path, output_path, 'train')\n",
    "preprocess_cb(root_path, output_path, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cb_to_tsv(in_path, split):\n",
    "    lines = []\n",
    "    ps, hs, labels = [], [], []\n",
    "    with open(os.path.join(in_path, split+'.jsonl'), 'r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            lines.append(json.loads(line))\n",
    "    for line in lines:\n",
    "        ps.append(line[\"premise\"])\n",
    "        hs.append(line[\"hypothesis\"])\n",
    "        if split != 'test':\n",
    "            labels.append(line[\"label\"])\n",
    "         \n",
    "    if split == 'val':\n",
    "        split = 'dev' \n",
    "    with open(os.path.join(in_path, split+'.tsv'), 'w', encoding='utf-8') as f:\n",
    "        if split != 'test':\n",
    "            f.write('premise\\thypothesis\\tlabel\\n')\n",
    "            for i in range(len(ps)):\n",
    "                f.write(ps[i]+'\\t'+hs[i]+'\\t'+labels[i]+'\\n')\n",
    "        else:\n",
    "            f.write('premise\\thypothesis\\n')\n",
    "            for i in range(len(ps)):\n",
    "                f.write(ps[i]+'\\t'+hs[i]+'\\n')\n",
    "    if split == 'dev':\n",
    "        split = 'valid'            \n",
    "    label_path = os.path.join(in_path, 'label')\n",
    "    if not os.path.exists(label_path):\n",
    "        os.mkdir(label_path)\n",
    "    with open(os.path.join(label_path, split), 'w', encoding='utf-8') as f:\n",
    "        for l in labels:\n",
    "            f.write(str(l)+'\\n')\n",
    "    if split == 'train':\n",
    "        with open(os.path.join(label_path, 'dict.txt'), 'w', encoding='utf-8') as f:\n",
    "            label_dict = Counter(labels)\n",
    "            for k, v in label_dict.items():\n",
    "                f.write(k+\" \"+str(v))\n",
    "                f.write('\\n')\n",
    "                \n",
    "root_path = '../../transformer/datasets/superglue/CB/'\n",
    "cb_to_tsv(root_path, 'train')\n",
    "cb_to_tsv(root_path, 'val')\n",
    "cb_to_tsv(root_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 2, 'b': 1})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def COPA_to_tsv(in_path, split):\n",
    "    lines = []\n",
    "    labels = []\n",
    "    questions = {'cause': 'because', 'effect': 'so'}    \n",
    "    with open(os.path.join(in_path, split+'.jsonl'), 'r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            l = json.loads(line)\n",
    "            p = l['premise']\n",
    "            c1 = l['choice1']\n",
    "            c2 = l['choice2']\n",
    "            q = l['question']\n",
    "            label = l['label']\n",
    "            lines.append(p[:-1] + ' ' + questions[q] + ' ' + c1)\n",
    "            lines.append(p[:-1] + ' ' + questions[q] + ' ' + c2)\n",
    "            labels.append(label)\n",
    "            labels.append(label)\n",
    "    if split == 'val':\n",
    "        split = 'dev' \n",
    "    with open(os.path.join(in_path, split+'.tsv'), 'w', encoding='utf-8') as f:\n",
    "        if split != 'test':\n",
    "            f.write('premise\\thypothesis\\tlabel\\n')\n",
    "            for i in range(len(ps)):\n",
    "                f.write(ps[i]+'\\t'+hs[i]+'\\t'+labels[i]+'\\n')\n",
    "        else:\n",
    "            f.write('premise\\thypothesis\\n')\n",
    "            for i in range(len(ps)):\n",
    "                f.write(ps[i]+'\\t'+hs[i]+'\\n')\n",
    "    if split == 'dev':\n",
    "        split = 'valid'            \n",
    "    label_path = os.path.join(in_path, 'label')\n",
    "    if not os.path.exists(label_path):\n",
    "        os.mkdir(label_path)\n",
    "    with open(os.path.join(label_path, split), 'w', encoding='utf-8') as f:\n",
    "        for l in labels:\n",
    "            f.write(str(l)+'\\n')\n",
    "    if split == 'train':\n",
    "        with open(os.path.join(label_path, 'dict.txt'), 'w', encoding='utf-8') as f:\n",
    "            label_dict = Counter(labels)\n",
    "            for k, v in label_dict.items():\n",
    "                f.write(k+\" \"+str(v))\n",
    "                f.write('\\n')\n",
    "                \n",
    "root_path = '../../transformer/datasets/superglue/CB/'\n",
    "cb_to_tsv(root_path, 'train')\n",
    "cb_to_tsv(root_path, 'val')\n",
    "cb_to_tsv(root_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BoolQ_to_tsv(in_path, split):\n",
    "    lines = []\n",
    "    ps, hs, labels = [], [], []\n",
    "    with open(os.path.join(in_path, split+'.jsonl'), 'r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            lines.append(json.loads(line))\n",
    "    for line in lines:\n",
    "        ps.append(line[\"question\"])\n",
    "        hs.append(line[\"passage\"])\n",
    "        if split != 'test':\n",
    "            labels.append(line[\"label\"])\n",
    "         \n",
    "    if split == 'val':\n",
    "        split = 'dev' \n",
    "    with open(os.path.join(in_path, split+'.tsv'), 'w', encoding='utf-8') as f:\n",
    "        if split != 'test':\n",
    "            f.write('question\\tpassage\\tlabel\\n')\n",
    "            for i in range(len(ps)):\n",
    "                f.write(ps[i]+'\\t'+hs[i]+'\\t'+str(labels[i])+'\\n')\n",
    "        else:\n",
    "            f.write('question\\tpassage\\n')\n",
    "            for i in range(len(ps)):\n",
    "                f.write(ps[i]+'\\t'+hs[i]+'\\n')\n",
    "    if split == 'dev':\n",
    "        split = 'valid'            \n",
    "    label_path = os.path.join(in_path, 'label')\n",
    "    if not os.path.exists(label_path):\n",
    "        os.mkdir(label_path)\n",
    "    with open(os.path.join(label_path, split), 'w', encoding='utf-8') as f:\n",
    "        for l in labels:\n",
    "            f.write(str(l)+'\\n')\n",
    "    if split == 'train':\n",
    "        with open(os.path.join(label_path, 'dict.txt'), 'w', encoding='utf-8') as f:\n",
    "            label_dict = Counter(labels)\n",
    "            for k, v in label_dict.items():\n",
    "                f.write(str(k)+\" \"+str(v))\n",
    "                f.write('\\n')\n",
    "                \n",
    "root_path = '../../transformer/datasets/superglue/BoolQ/'\n",
    "BoolQ_to_tsv(root_path, 'train')\n",
    "BoolQ_to_tsv(root_path, 'val')\n",
    "BoolQ_to_tsv(root_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 14, 14])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def BoolQ_to_tsv(in_path, split):\n",
    "    lines = []\n",
    "    ps, hs, labels = [], [], []\n",
    "    with open(os.path.join(in_path, split+'.jsonl'), 'r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            lines.append(json.loads(line))\n",
    "    for line in lines:\n",
    "        ps.append(line[\"question\"])\n",
    "        hs.append(line[\"passage\"])\n",
    "        if split != 'test':\n",
    "            labels.append(line[\"label\"])\n",
    "         \n",
    "    if split == 'val':\n",
    "        split = 'dev' \n",
    "    with open(os.path.join(in_path, split+'.tsv'), 'w', encoding='utf-8') as f:\n",
    "        if split != 'test':\n",
    "            f.write('question\\tpassage\\tlabel\\n')\n",
    "            for i in range(len(ps)):\n",
    "                f.write(ps[i]+'\\t'+hs[i]+'\\t'+str(labels[i])+'\\n')\n",
    "        else:\n",
    "            f.write('question\\tpassage\\n')\n",
    "            for i in range(len(ps)):\n",
    "                f.write(ps[i]+'\\t'+hs[i]+'\\n')\n",
    "    if split == 'dev':\n",
    "        split = 'valid'            \n",
    "    label_path = os.path.join(in_path, 'label')\n",
    "    if not os.path.exists(label_path):\n",
    "        os.mkdir(label_path)\n",
    "    with open(os.path.join(label_path, split), 'w', encoding='utf-8') as f:\n",
    "        for l in labels:\n",
    "            f.write(str(l)+'\\n')\n",
    "    if split == 'train':\n",
    "        with open(os.path.join(label_path, 'dict.txt'), 'w', encoding='utf-8') as f:\n",
    "            label_dict = Counter(labels)\n",
    "            for k, v in label_dict.items():\n",
    "                f.write(str(k)+\" \"+str(v))\n",
    "                f.write('\\n')\n",
    "                \n",
    "root_path = '../../transformer/datasets/superglue/BoolQ/'\n",
    "BoolQ_to_tsv(root_path, 'train')\n",
    "BoolQ_to_tsv(root_path, 'val')\n",
    "BoolQ_to_tsv(root_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
