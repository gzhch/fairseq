{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import importlib\n",
    "import sys\n",
    "#importlib.reload(sys.modules['fairseq.models.roberta'])\n",
    "from fairseq.models.roberta import RobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_model = RobertaModel.from_pretrained(\n",
    "    'tmp/out',\n",
    "    checkpoint_file='checkpoint_best.pt',\n",
    "    data_name_or_path='/new_home/zhuocheng/FastBERT/examples/roberta/glue/MRPC-bin/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaHubInterface(\n",
       "  (model): RobertaModel(\n",
       "    (encoder): RobertaEncoder(\n",
       "      (sentence_encoder): TransformerEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(514, 1024, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (v_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (q_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (out_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): RFTLinear(in_features=1024, out_features=4096, bias=True, ft_rate=0.05)\n",
       "            (fc2): RFTLinear(in_features=4096, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (v_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (q_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (out_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): RFTLinear(in_features=1024, out_features=4096, bias=True, ft_rate=0.05)\n",
       "            (fc2): RFTLinear(in_features=4096, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (v_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (q_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (out_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): RFTLinear(in_features=1024, out_features=4096, bias=True, ft_rate=0.05)\n",
       "            (fc2): RFTLinear(in_features=4096, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (v_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (q_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (out_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): RFTLinear(in_features=1024, out_features=4096, bias=True, ft_rate=0.05)\n",
       "            (fc2): RFTLinear(in_features=4096, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (v_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (q_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (out_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): RFTLinear(in_features=1024, out_features=4096, bias=True, ft_rate=0.05)\n",
       "            (fc2): RFTLinear(in_features=4096, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (v_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (q_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (out_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): RFTLinear(in_features=1024, out_features=4096, bias=True, ft_rate=0.05)\n",
       "            (fc2): RFTLinear(in_features=4096, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (v_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (q_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (out_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): RFTLinear(in_features=1024, out_features=4096, bias=True, ft_rate=0.05)\n",
       "            (fc2): RFTLinear(in_features=4096, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (v_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (q_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (out_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): RFTLinear(in_features=1024, out_features=4096, bias=True, ft_rate=0.05)\n",
       "            (fc2): RFTLinear(in_features=4096, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (v_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (q_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (out_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): RFTLinear(in_features=1024, out_features=4096, bias=True, ft_rate=0.05)\n",
       "            (fc2): RFTLinear(in_features=4096, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (v_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (q_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (out_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): RFTLinear(in_features=1024, out_features=4096, bias=True, ft_rate=0.05)\n",
       "            (fc2): RFTLinear(in_features=4096, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (v_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (q_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (out_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): RFTLinear(in_features=1024, out_features=4096, bias=True, ft_rate=0.05)\n",
       "            (fc2): RFTLinear(in_features=4096, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (v_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (q_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (out_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): RFTLinear(in_features=1024, out_features=4096, bias=True, ft_rate=0.05)\n",
       "            (fc2): RFTLinear(in_features=4096, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (12): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (v_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (q_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (out_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): RFTLinear(in_features=1024, out_features=4096, bias=True, ft_rate=0.05)\n",
       "            (fc2): RFTLinear(in_features=4096, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (13): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (v_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (q_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (out_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): RFTLinear(in_features=1024, out_features=4096, bias=True, ft_rate=0.05)\n",
       "            (fc2): RFTLinear(in_features=4096, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (14): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (v_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (q_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (out_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): RFTLinear(in_features=1024, out_features=4096, bias=True, ft_rate=0.05)\n",
       "            (fc2): RFTLinear(in_features=4096, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (15): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (v_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (q_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (out_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): RFTLinear(in_features=1024, out_features=4096, bias=True, ft_rate=0.05)\n",
       "            (fc2): RFTLinear(in_features=4096, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (16): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (v_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (q_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (out_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): RFTLinear(in_features=1024, out_features=4096, bias=True, ft_rate=0.05)\n",
       "            (fc2): RFTLinear(in_features=4096, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (17): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (v_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (q_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (out_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): RFTLinear(in_features=1024, out_features=4096, bias=True, ft_rate=0.05)\n",
       "            (fc2): RFTLinear(in_features=4096, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (18): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (v_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (q_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (out_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): RFTLinear(in_features=1024, out_features=4096, bias=True, ft_rate=0.05)\n",
       "            (fc2): RFTLinear(in_features=4096, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (19): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (v_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (q_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (out_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): RFTLinear(in_features=1024, out_features=4096, bias=True, ft_rate=0.05)\n",
       "            (fc2): RFTLinear(in_features=4096, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (20): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (v_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (q_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (out_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): RFTLinear(in_features=1024, out_features=4096, bias=True, ft_rate=0.05)\n",
       "            (fc2): RFTLinear(in_features=4096, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (21): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (v_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (q_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (out_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): RFTLinear(in_features=1024, out_features=4096, bias=True, ft_rate=0.05)\n",
       "            (fc2): RFTLinear(in_features=4096, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (22): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (v_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (q_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (out_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): RFTLinear(in_features=1024, out_features=4096, bias=True, ft_rate=0.05)\n",
       "            (fc2): RFTLinear(in_features=4096, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (23): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (v_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (q_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "              (out_proj): RFTLinear(in_features=1024, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): RFTLinear(in_features=1024, out_features=4096, bias=True, ft_rate=0.05)\n",
       "            (fc2): RFTLinear(in_features=4096, out_features=1024, bias=True, ft_rate=0.05)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (classification_heads): ModuleDict(\n",
       "      (sentence_classification_head): RobertaClassificationHead(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rft = RobertaModel.from_pretrained(\n",
    "    '/new_home/zhuocheng/blobs/gzhch/ckpt/large/CoLA/30-15-16-1e-4-5e-2-2-1',\n",
    "    checkpoint_file='checkpoint_best.pt',\n",
    "    data_name_or_path='/new_home/zhuocheng/FastBERT/examples/roberta/glue/CoLA-bin/'\n",
    ")\n",
    "rft.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaHubInterface(\n",
       "  (model): RobertaModel(\n",
       "    (encoder): RobertaEncoder(\n",
       "      (sentence_encoder): TransformerEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(514, 1024, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (12): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (13): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (14): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (15): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (16): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (17): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (18): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (19): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (20): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (21): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (22): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (23): TransformerEncoderLayer(\n",
       "            (l1_penalty): L1Loss()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (classification_heads): ModuleDict(\n",
       "      (sentence_classification_head): RobertaClassificationHead(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fft = RobertaModel.from_pretrained(\n",
    "    '/new_home/zhuocheng/blobs/gzhch/ckpt/large/CoLA/30-15-16-1e-5-0-2-1',\n",
    "    checkpoint_file='checkpoint_best.pt',\n",
    "    data_name_or_path='/new_home/zhuocheng/FastBERT/examples/roberta/glue/CoLA-bin/'\n",
    ")\n",
    "fft.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.encoder.sentence_encoder.embed_tokens.weight torch.Size([50265, 1024])\n",
      "model.encoder.sentence_encoder.embed_positions.weight torch.Size([514, 1024])\n",
      "model.encoder.sentence_encoder.layernorm_embedding.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layernorm_embedding.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.0.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.0.self_attn.k_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.0.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.0.self_attn.v_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.0.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.0.self_attn.q_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.0.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.0.self_attn.out_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.0.self_attn_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.0.self_attn_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.0.fc1.weight torch.Size([4096, 1024])\n",
      "model.encoder.sentence_encoder.layers.0.fc1.bias torch.Size([4096])\n",
      "model.encoder.sentence_encoder.layers.0.fc2.weight torch.Size([1024, 4096])\n",
      "model.encoder.sentence_encoder.layers.0.fc2.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.0.final_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.0.final_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.1.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.1.self_attn.k_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.1.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.1.self_attn.v_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.1.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.1.self_attn.q_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.1.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.1.self_attn.out_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.1.self_attn_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.1.self_attn_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.1.fc1.weight torch.Size([4096, 1024])\n",
      "model.encoder.sentence_encoder.layers.1.fc1.bias torch.Size([4096])\n",
      "model.encoder.sentence_encoder.layers.1.fc2.weight torch.Size([1024, 4096])\n",
      "model.encoder.sentence_encoder.layers.1.fc2.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.1.final_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.1.final_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.2.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.2.self_attn.k_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.2.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.2.self_attn.v_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.2.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.2.self_attn.q_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.2.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.2.self_attn.out_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.2.self_attn_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.2.self_attn_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.2.fc1.weight torch.Size([4096, 1024])\n",
      "model.encoder.sentence_encoder.layers.2.fc1.bias torch.Size([4096])\n",
      "model.encoder.sentence_encoder.layers.2.fc2.weight torch.Size([1024, 4096])\n",
      "model.encoder.sentence_encoder.layers.2.fc2.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.2.final_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.2.final_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.3.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.3.self_attn.k_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.3.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.3.self_attn.v_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.3.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.3.self_attn.q_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.3.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.3.self_attn.out_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.3.self_attn_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.3.self_attn_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.3.fc1.weight torch.Size([4096, 1024])\n",
      "model.encoder.sentence_encoder.layers.3.fc1.bias torch.Size([4096])\n",
      "model.encoder.sentence_encoder.layers.3.fc2.weight torch.Size([1024, 4096])\n",
      "model.encoder.sentence_encoder.layers.3.fc2.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.3.final_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.3.final_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.4.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.4.self_attn.k_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.4.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.4.self_attn.v_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.4.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.4.self_attn.q_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.4.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.4.self_attn.out_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.4.self_attn_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.4.self_attn_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.4.fc1.weight torch.Size([4096, 1024])\n",
      "model.encoder.sentence_encoder.layers.4.fc1.bias torch.Size([4096])\n",
      "model.encoder.sentence_encoder.layers.4.fc2.weight torch.Size([1024, 4096])\n",
      "model.encoder.sentence_encoder.layers.4.fc2.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.4.final_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.4.final_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.5.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.5.self_attn.k_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.5.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.5.self_attn.v_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.5.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.5.self_attn.q_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.5.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.5.self_attn.out_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.5.self_attn_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.5.self_attn_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.5.fc1.weight torch.Size([4096, 1024])\n",
      "model.encoder.sentence_encoder.layers.5.fc1.bias torch.Size([4096])\n",
      "model.encoder.sentence_encoder.layers.5.fc2.weight torch.Size([1024, 4096])\n",
      "model.encoder.sentence_encoder.layers.5.fc2.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.5.final_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.5.final_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.6.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.6.self_attn.k_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.6.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.6.self_attn.v_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.6.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.6.self_attn.q_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.6.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.6.self_attn.out_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.6.self_attn_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.6.self_attn_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.6.fc1.weight torch.Size([4096, 1024])\n",
      "model.encoder.sentence_encoder.layers.6.fc1.bias torch.Size([4096])\n",
      "model.encoder.sentence_encoder.layers.6.fc2.weight torch.Size([1024, 4096])\n",
      "model.encoder.sentence_encoder.layers.6.fc2.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.6.final_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.6.final_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.7.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.7.self_attn.k_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.7.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.7.self_attn.v_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.7.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.7.self_attn.q_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.7.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.7.self_attn.out_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.7.self_attn_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.7.self_attn_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.7.fc1.weight torch.Size([4096, 1024])\n",
      "model.encoder.sentence_encoder.layers.7.fc1.bias torch.Size([4096])\n",
      "model.encoder.sentence_encoder.layers.7.fc2.weight torch.Size([1024, 4096])\n",
      "model.encoder.sentence_encoder.layers.7.fc2.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.7.final_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.7.final_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.8.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.8.self_attn.k_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.8.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.8.self_attn.v_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.8.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.8.self_attn.q_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.8.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.8.self_attn.out_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.8.self_attn_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.8.self_attn_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.8.fc1.weight torch.Size([4096, 1024])\n",
      "model.encoder.sentence_encoder.layers.8.fc1.bias torch.Size([4096])\n",
      "model.encoder.sentence_encoder.layers.8.fc2.weight torch.Size([1024, 4096])\n",
      "model.encoder.sentence_encoder.layers.8.fc2.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.8.final_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.8.final_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.9.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.9.self_attn.k_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.9.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.9.self_attn.v_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.9.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.9.self_attn.q_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.9.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.9.self_attn.out_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.9.self_attn_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.9.self_attn_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.9.fc1.weight torch.Size([4096, 1024])\n",
      "model.encoder.sentence_encoder.layers.9.fc1.bias torch.Size([4096])\n",
      "model.encoder.sentence_encoder.layers.9.fc2.weight torch.Size([1024, 4096])\n",
      "model.encoder.sentence_encoder.layers.9.fc2.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.9.final_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.9.final_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.10.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.10.self_attn.k_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.10.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.10.self_attn.v_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.10.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.10.self_attn.q_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.10.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.10.self_attn.out_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.10.self_attn_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.10.self_attn_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.10.fc1.weight torch.Size([4096, 1024])\n",
      "model.encoder.sentence_encoder.layers.10.fc1.bias torch.Size([4096])\n",
      "model.encoder.sentence_encoder.layers.10.fc2.weight torch.Size([1024, 4096])\n",
      "model.encoder.sentence_encoder.layers.10.fc2.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.10.final_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.10.final_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.11.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.11.self_attn.k_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.11.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.11.self_attn.v_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.11.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.11.self_attn.q_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.11.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.11.self_attn.out_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.11.self_attn_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.11.self_attn_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.11.fc1.weight torch.Size([4096, 1024])\n",
      "model.encoder.sentence_encoder.layers.11.fc1.bias torch.Size([4096])\n",
      "model.encoder.sentence_encoder.layers.11.fc2.weight torch.Size([1024, 4096])\n",
      "model.encoder.sentence_encoder.layers.11.fc2.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.11.final_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.11.final_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.12.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.12.self_attn.k_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.12.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.12.self_attn.v_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.12.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.12.self_attn.q_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.12.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.12.self_attn.out_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.12.self_attn_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.12.self_attn_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.12.fc1.weight torch.Size([4096, 1024])\n",
      "model.encoder.sentence_encoder.layers.12.fc1.bias torch.Size([4096])\n",
      "model.encoder.sentence_encoder.layers.12.fc2.weight torch.Size([1024, 4096])\n",
      "model.encoder.sentence_encoder.layers.12.fc2.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.12.final_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.12.final_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.13.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.13.self_attn.k_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.13.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.13.self_attn.v_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.13.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.13.self_attn.q_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.13.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.13.self_attn.out_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.13.self_attn_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.13.self_attn_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.13.fc1.weight torch.Size([4096, 1024])\n",
      "model.encoder.sentence_encoder.layers.13.fc1.bias torch.Size([4096])\n",
      "model.encoder.sentence_encoder.layers.13.fc2.weight torch.Size([1024, 4096])\n",
      "model.encoder.sentence_encoder.layers.13.fc2.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.13.final_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.13.final_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.14.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.14.self_attn.k_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.14.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.14.self_attn.v_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.14.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.14.self_attn.q_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.14.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.14.self_attn.out_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.14.self_attn_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.14.self_attn_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.14.fc1.weight torch.Size([4096, 1024])\n",
      "model.encoder.sentence_encoder.layers.14.fc1.bias torch.Size([4096])\n",
      "model.encoder.sentence_encoder.layers.14.fc2.weight torch.Size([1024, 4096])\n",
      "model.encoder.sentence_encoder.layers.14.fc2.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.14.final_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.14.final_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.15.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.15.self_attn.k_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.15.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.15.self_attn.v_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.15.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.15.self_attn.q_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.15.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.15.self_attn.out_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.15.self_attn_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.15.self_attn_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.15.fc1.weight torch.Size([4096, 1024])\n",
      "model.encoder.sentence_encoder.layers.15.fc1.bias torch.Size([4096])\n",
      "model.encoder.sentence_encoder.layers.15.fc2.weight torch.Size([1024, 4096])\n",
      "model.encoder.sentence_encoder.layers.15.fc2.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.15.final_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.15.final_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.16.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.16.self_attn.k_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.16.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.16.self_attn.v_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.16.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.16.self_attn.q_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.16.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.16.self_attn.out_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.16.self_attn_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.16.self_attn_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.16.fc1.weight torch.Size([4096, 1024])\n",
      "model.encoder.sentence_encoder.layers.16.fc1.bias torch.Size([4096])\n",
      "model.encoder.sentence_encoder.layers.16.fc2.weight torch.Size([1024, 4096])\n",
      "model.encoder.sentence_encoder.layers.16.fc2.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.16.final_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.16.final_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.17.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.17.self_attn.k_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.17.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.17.self_attn.v_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.17.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.17.self_attn.q_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.17.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.17.self_attn.out_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.17.self_attn_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.17.self_attn_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.17.fc1.weight torch.Size([4096, 1024])\n",
      "model.encoder.sentence_encoder.layers.17.fc1.bias torch.Size([4096])\n",
      "model.encoder.sentence_encoder.layers.17.fc2.weight torch.Size([1024, 4096])\n",
      "model.encoder.sentence_encoder.layers.17.fc2.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.17.final_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.17.final_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.18.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.18.self_attn.k_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.18.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.18.self_attn.v_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.18.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.18.self_attn.q_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.18.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.18.self_attn.out_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.18.self_attn_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.18.self_attn_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.18.fc1.weight torch.Size([4096, 1024])\n",
      "model.encoder.sentence_encoder.layers.18.fc1.bias torch.Size([4096])\n",
      "model.encoder.sentence_encoder.layers.18.fc2.weight torch.Size([1024, 4096])\n",
      "model.encoder.sentence_encoder.layers.18.fc2.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.18.final_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.18.final_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.19.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.19.self_attn.k_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.19.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.19.self_attn.v_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.19.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.19.self_attn.q_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.19.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.19.self_attn.out_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.19.self_attn_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.19.self_attn_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.19.fc1.weight torch.Size([4096, 1024])\n",
      "model.encoder.sentence_encoder.layers.19.fc1.bias torch.Size([4096])\n",
      "model.encoder.sentence_encoder.layers.19.fc2.weight torch.Size([1024, 4096])\n",
      "model.encoder.sentence_encoder.layers.19.fc2.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.19.final_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.19.final_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.20.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.20.self_attn.k_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.20.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.20.self_attn.v_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.20.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.20.self_attn.q_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.20.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.20.self_attn.out_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.20.self_attn_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.20.self_attn_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.20.fc1.weight torch.Size([4096, 1024])\n",
      "model.encoder.sentence_encoder.layers.20.fc1.bias torch.Size([4096])\n",
      "model.encoder.sentence_encoder.layers.20.fc2.weight torch.Size([1024, 4096])\n",
      "model.encoder.sentence_encoder.layers.20.fc2.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.20.final_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.20.final_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.21.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.21.self_attn.k_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.21.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.21.self_attn.v_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.21.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.21.self_attn.q_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.21.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.21.self_attn.out_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.21.self_attn_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.21.self_attn_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.21.fc1.weight torch.Size([4096, 1024])\n",
      "model.encoder.sentence_encoder.layers.21.fc1.bias torch.Size([4096])\n",
      "model.encoder.sentence_encoder.layers.21.fc2.weight torch.Size([1024, 4096])\n",
      "model.encoder.sentence_encoder.layers.21.fc2.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.21.final_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.21.final_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.22.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.22.self_attn.k_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.22.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.22.self_attn.v_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.22.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.22.self_attn.q_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.22.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.22.self_attn.out_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.22.self_attn_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.22.self_attn_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.22.fc1.weight torch.Size([4096, 1024])\n",
      "model.encoder.sentence_encoder.layers.22.fc1.bias torch.Size([4096])\n",
      "model.encoder.sentence_encoder.layers.22.fc2.weight torch.Size([1024, 4096])\n",
      "model.encoder.sentence_encoder.layers.22.fc2.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.22.final_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.22.final_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.23.self_attn.k_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.23.self_attn.k_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.23.self_attn.v_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.23.self_attn.v_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.23.self_attn.q_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.23.self_attn.q_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.23.self_attn.out_proj.weight torch.Size([1024, 1024])\n",
      "model.encoder.sentence_encoder.layers.23.self_attn.out_proj.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.23.self_attn_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.23.self_attn_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.23.fc1.weight torch.Size([4096, 1024])\n",
      "model.encoder.sentence_encoder.layers.23.fc1.bias torch.Size([4096])\n",
      "model.encoder.sentence_encoder.layers.23.fc2.weight torch.Size([1024, 4096])\n",
      "model.encoder.sentence_encoder.layers.23.fc2.bias torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.23.final_layer_norm.weight torch.Size([1024])\n",
      "model.encoder.sentence_encoder.layers.23.final_layer_norm.bias torch.Size([1024])\n",
      "model.encoder.lm_head.bias torch.Size([50265])\n",
      "model.encoder.lm_head.dense.weight torch.Size([1024, 1024])\n",
      "model.encoder.lm_head.dense.bias torch.Size([1024])\n",
      "model.encoder.lm_head.layer_norm.weight torch.Size([1024])\n",
      "model.encoder.lm_head.layer_norm.bias torch.Size([1024])\n",
      "model.classification_heads.sentence_classification_head.dense.weight torch.Size([1024, 1024])\n",
      "model.classification_heads.sentence_classification_head.dense.bias torch.Size([1024])\n",
      "model.classification_heads.sentence_classification_head.out_proj.weight torch.Size([2, 1024])\n",
      "model.classification_heads.sentence_classification_head.out_proj.bias torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "names = []\n",
    "shapes = []\n",
    "for n, p in l1_model.named_parameters():\n",
    "    if n.endswith('bias') or n.endswith('weight'):\n",
    "        print(n, p.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_layers = l1_model.model.encoder.sentence_encoder.layers\n",
    "rft_layers = rft.model.encoder.sentence_encoder.layers\n",
    "fft_layers = fft.model.encoder.sentence_encoder.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l1_res = []\n",
    "for i in l1_layers:\n",
    "    modules = []\n",
    "    modules.append(i.self_attn.q_proj)\n",
    "    modules.append(i.self_attn.k_proj)\n",
    "    modules.append(i.self_attn.v_proj)\n",
    "    modules.append(i.self_attn.out_proj)\n",
    "    modules.append(i.self_attn_layer_norm)\n",
    "    modules.append(i.fc1)\n",
    "    modules.append(i.fc2)\n",
    "    modules.append(i.final_layer_norm)\n",
    "    t = []\n",
    "    for j in modules:\n",
    "        t.append((torch.abs(j.weight-j.weight_upd)).sum().tolist())\n",
    "        t.append((torch.abs(j.bias-j.bias_upd)).sum().tolist())\n",
    "    l1_res.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff(a):\n",
    "    weight = a.weight * (a.th_w.cpu() > a.p) + a.weight_upd * (a.th_w.cpu() <= a.p)\n",
    "    bias = a.bias * (a.th_b.cpu() > a.p) + a.bias_upd * (a.th_b.cpu() <= a.p)\n",
    "    return torch.abs(weight - a.weight).sum().tolist(), torch.abs(bias - a.bias).sum().tolist()\n",
    "rft_res = []\n",
    "for i in rft_layers:\n",
    "    modules = []\n",
    "    modules.append(i.self_attn.q_proj)\n",
    "    modules.append(i.self_attn.k_proj)\n",
    "    modules.append(i.self_attn.v_proj)\n",
    "    modules.append(i.self_attn.out_proj)\n",
    "    modules.append(i.fc1)\n",
    "    modules.append(i.fc2)\n",
    "    t = []\n",
    "    for j in modules:\n",
    "        diff_w, diff_b = diff(j)\n",
    "        t.append(diff_w)\n",
    "        t.append(diff_b)\n",
    "    rft_res.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_res = []\n",
    "for i in range(len(rft_layers)):\n",
    "    m = []\n",
    "    m.append([rft_layers[i].self_attn.q_proj, fft_layers[i].self_attn.q_proj])\n",
    "    m.append([rft_layers[i].self_attn.k_proj, fft_layers[i].self_attn.k_proj])\n",
    "    m.append([rft_layers[i].self_attn.v_proj, fft_layers[i].self_attn.v_proj])\n",
    "    m.append([rft_layers[i].self_attn.out_proj, fft_layers[i].self_attn.out_proj])\n",
    "    m.append([rft_layers[i].self_attn_layer_norm, fft_layers[i].self_attn_layer_norm])\n",
    "    m.append([rft_layers[i].fc1, fft_layers[i].fc1])\n",
    "    m.append([rft_layers[i].fc2, fft_layers[i].fc2])\n",
    "    m.append([rft_layers[i].final_layer_norm, fft_layers[i].final_layer_norm])\n",
    "    t = []\n",
    "    for j in m:\n",
    "        t.append((torch.abs(j[0].weight-j[1].weight)).sum().tolist())\n",
    "        t.append((torch.abs(j[0].bias-j[1].bias)).sum().tolist())\n",
    "    fft_res.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerEncoderLayer(\n",
       "  (l1_penalty): L1Loss()\n",
       "  (self_attn): MultiheadAttention(\n",
       "    (dropout_module): FairseqDropout()\n",
       "    (k_proj): L1Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (v_proj): L1Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (q_proj): L1Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (out_proj): L1Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (self_attn_layer_norm): L1LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout_module): FairseqDropout()\n",
       "  (activation_dropout_module): FairseqDropout()\n",
       "  (fc1): L1Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (fc2): L1Linear(in_features=4096, out_features=1024, bias=True)\n",
       "  (final_layer_norm): L1LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[36.799224853515625,\n",
       "  0.0477219820022583,\n",
       "  37.445411682128906,\n",
       "  0.00817042589187622,\n",
       "  56.94488525390625,\n",
       "  0.18981492519378662,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [28.166507720947266,\n",
       "  0.04522472620010376,\n",
       "  26.782699584960938,\n",
       "  0.007979333400726318,\n",
       "  77.10852813720703,\n",
       "  0.3120831251144409,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [16.638568878173828,\n",
       "  0.026233553886413574,\n",
       "  17.42073631286621,\n",
       "  0.006244003772735596,\n",
       "  63.862030029296875,\n",
       "  0.2558266520500183,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [30.135814666748047,\n",
       "  0.058978378772735596,\n",
       "  27.549476623535156,\n",
       "  0.008238613605499268,\n",
       "  51.2159423828125,\n",
       "  0.26303791999816895,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [24.941787719726562,\n",
       "  0.04169726371765137,\n",
       "  22.75625228881836,\n",
       "  0.007937252521514893,\n",
       "  36.63056945800781,\n",
       "  0.17221564054489136,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [15.049750328063965,\n",
       "  0.023265957832336426,\n",
       "  13.855289459228516,\n",
       "  0.008389174938201904,\n",
       "  28.764751434326172,\n",
       "  0.14839696884155273,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [16.771076202392578,\n",
       "  0.034080326557159424,\n",
       "  16.107189178466797,\n",
       "  0.008198201656341553,\n",
       "  34.25643539428711,\n",
       "  0.1418771743774414,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [16.945003509521484,\n",
       "  0.02731025218963623,\n",
       "  16.389690399169922,\n",
       "  0.00802302360534668,\n",
       "  37.46525192260742,\n",
       "  0.1826828122138977,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [18.11176300048828,\n",
       "  0.03543555736541748,\n",
       "  17.81871795654297,\n",
       "  0.007679760456085205,\n",
       "  46.38002014160156,\n",
       "  0.1871970295906067,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [18.959407806396484,\n",
       "  0.034590184688568115,\n",
       "  18.18243980407715,\n",
       "  0.008203864097595215,\n",
       "  42.84563064575195,\n",
       "  0.1764509677886963,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [25.161190032958984,\n",
       "  0.0404013991355896,\n",
       "  24.904476165771484,\n",
       "  0.00820779800415039,\n",
       "  46.754356384277344,\n",
       "  0.15473610162734985,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [19.582805633544922,\n",
       "  0.0401042103767395,\n",
       "  20.08396339416504,\n",
       "  0.007971763610839844,\n",
       "  44.67402267456055,\n",
       "  0.15049290657043457,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [18.035335540771484,\n",
       "  0.034659743309020996,\n",
       "  17.4080867767334,\n",
       "  0.007531285285949707,\n",
       "  45.29826736450195,\n",
       "  0.13722896575927734,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [22.257675170898438,\n",
       "  0.037805914878845215,\n",
       "  21.258081436157227,\n",
       "  0.007516264915466309,\n",
       "  41.49705123901367,\n",
       "  0.1294041872024536,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [16.445396423339844,\n",
       "  0.03151357173919678,\n",
       "  15.781496047973633,\n",
       "  0.006942689418792725,\n",
       "  33.43994140625,\n",
       "  0.10883229970932007,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [16.702224731445312,\n",
       "  0.029292583465576172,\n",
       "  17.025121688842773,\n",
       "  0.007283508777618408,\n",
       "  37.48846435546875,\n",
       "  0.11447376012802124,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [18.537357330322266,\n",
       "  0.03336024284362793,\n",
       "  18.870384216308594,\n",
       "  0.007735550403594971,\n",
       "  30.407718658447266,\n",
       "  0.09943324327468872,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [16.372018814086914,\n",
       "  0.02660435438156128,\n",
       "  17.306262969970703,\n",
       "  0.006926119327545166,\n",
       "  25.052745819091797,\n",
       "  0.0805550217628479,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [11.744514465332031,\n",
       "  0.017433583736419678,\n",
       "  11.181282997131348,\n",
       "  0.006958961486816406,\n",
       "  19.66297149658203,\n",
       "  0.07494306564331055,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [10.734718322753906,\n",
       "  0.015376269817352295,\n",
       "  9.480599403381348,\n",
       "  0.007222890853881836,\n",
       "  22.767444610595703,\n",
       "  0.057055771350860596,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [8.97669792175293,\n",
       "  0.01199638843536377,\n",
       "  8.210392951965332,\n",
       "  0.0065048933029174805,\n",
       "  19.042871475219727,\n",
       "  0.04334217309951782,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [8.58176326751709,\n",
       "  0.009798109531402588,\n",
       "  7.976533889770508,\n",
       "  0.006492137908935547,\n",
       "  17.48955726623535,\n",
       "  0.035042524337768555,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [8.009284973144531,\n",
       "  0.008076250553131104,\n",
       "  7.789874076843262,\n",
       "  0.006078183650970459,\n",
       "  17.38149642944336,\n",
       "  0.028268158435821533,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [9.362685203552246,\n",
       "  0.010471940040588379,\n",
       "  8.697298049926758,\n",
       "  0.006325721740722656,\n",
       "  18.440887451171875,\n",
       "  0.01845729351043701,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[52.800601959228516,\n",
       "  0.16620635986328125,\n",
       "  49.058998107910156,\n",
       "  0.004962801933288574,\n",
       "  47.12199401855469,\n",
       "  0.023984909057617188,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [69.14986419677734,\n",
       "  0.198516845703125,\n",
       "  65.40501403808594,\n",
       "  0.006791889667510986,\n",
       "  46.8350830078125,\n",
       "  0.03419053554534912,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [66.57344055175781,\n",
       "  0.09325790405273438,\n",
       "  64.46003723144531,\n",
       "  0.0030852556228637695,\n",
       "  40.38270950317383,\n",
       "  0.016836881637573242,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [62.826202392578125,\n",
       "  0.10793447494506836,\n",
       "  60.79346466064453,\n",
       "  0.009508073329925537,\n",
       "  49.5035400390625,\n",
       "  0.03241771459579468,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [60.99873352050781,\n",
       "  0.13822078704833984,\n",
       "  57.925052642822266,\n",
       "  0.0030320286750793457,\n",
       "  50.39532470703125,\n",
       "  0.024923324584960938,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [61.59055709838867,\n",
       "  0.13995742797851562,\n",
       "  57.81449508666992,\n",
       "  0.00548630952835083,\n",
       "  52.81980514526367,\n",
       "  0.026035070419311523,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [63.75574493408203,\n",
       "  0.1113128662109375,\n",
       "  59.76084518432617,\n",
       "  0.003850102424621582,\n",
       "  52.78770446777344,\n",
       "  0.015197038650512695,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [66.11843872070312,\n",
       "  0.15734195709228516,\n",
       "  61.75050735473633,\n",
       "  0.010079681873321533,\n",
       "  53.53058624267578,\n",
       "  0.024338483810424805,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [68.19977569580078,\n",
       "  0.11097872257232666,\n",
       "  63.710121154785156,\n",
       "  0.002085864543914795,\n",
       "  50.07891845703125,\n",
       "  0.038266122341156006,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [66.72053527832031,\n",
       "  0.07234477996826172,\n",
       "  64.04708862304688,\n",
       "  0.00254899263381958,\n",
       "  52.12720489501953,\n",
       "  0.011653244495391846,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [71.59306335449219,\n",
       "  0.07000064849853516,\n",
       "  68.12675476074219,\n",
       "  0.006109356880187988,\n",
       "  48.94355392456055,\n",
       "  0.01941394805908203,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [69.41380310058594,\n",
       "  0.0970613956451416,\n",
       "  67.54698181152344,\n",
       "  0.001194775104522705,\n",
       "  51.405006408691406,\n",
       "  0.037603139877319336,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [66.15599060058594,\n",
       "  0.09972906112670898,\n",
       "  64.30919647216797,\n",
       "  0.01247549057006836,\n",
       "  52.87692642211914,\n",
       "  0.01809072494506836,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [69.03952026367188,\n",
       "  0.11521494388580322,\n",
       "  65.94866943359375,\n",
       "  0.001148998737335205,\n",
       "  53.45663070678711,\n",
       "  0.025729060173034668,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [69.17174530029297,\n",
       "  0.12896347045898438,\n",
       "  65.19873046875,\n",
       "  0.016882121562957764,\n",
       "  56.015933990478516,\n",
       "  0.021736502647399902,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [68.14495086669922,\n",
       "  0.09486007690429688,\n",
       "  64.44171142578125,\n",
       "  0.0026529431343078613,\n",
       "  56.132659912109375,\n",
       "  0.011544227600097656,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [68.88248443603516,\n",
       "  0.09960412979125977,\n",
       "  64.9749526977539,\n",
       "  0.010713517665863037,\n",
       "  53.448219299316406,\n",
       "  0.019210875034332275,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [68.16289520263672,\n",
       "  0.10282588005065918,\n",
       "  65.45277404785156,\n",
       "  0.00031834840774536133,\n",
       "  54.98662567138672,\n",
       "  0.010959625244140625,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [70.01258087158203,\n",
       "  0.05135452747344971,\n",
       "  66.84342956542969,\n",
       "  0.01943659782409668,\n",
       "  53.06479263305664,\n",
       "  0.011587023735046387,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [67.65119934082031,\n",
       "  0.08566427230834961,\n",
       "  66.36121368408203,\n",
       "  0.009860992431640625,\n",
       "  50.33774948120117,\n",
       "  0.02129840850830078,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [68.51377868652344,\n",
       "  0.0710601806640625,\n",
       "  66.65235900878906,\n",
       "  0.02693331241607666,\n",
       "  47.01787567138672,\n",
       "  0.023647785186767578,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [65.88569641113281,\n",
       "  0.08602714538574219,\n",
       "  65.36663055419922,\n",
       "  0.009298980236053467,\n",
       "  46.44406509399414,\n",
       "  0.029522418975830078,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [68.74324035644531,\n",
       "  0.11992740631103516,\n",
       "  66.17939758300781,\n",
       "  0.05420655012130737,\n",
       "  46.255069732666016,\n",
       "  0.028419792652130127,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [65.24476623535156,\n",
       "  0.11627960205078125,\n",
       "  64.13336181640625,\n",
       "  0.01153421401977539,\n",
       "  51.617706298828125,\n",
       "  0.021724700927734375,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rft_res    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[544.9857788085938,\n",
       "  0.8489736318588257,\n",
       "  543.70361328125,\n",
       "  0.10999637842178345,\n",
       "  525.2040405273438,\n",
       "  0.41396844387054443,\n",
       "  524.9215087890625,\n",
       "  0.5215989351272583,\n",
       "  23.240234375,\n",
       "  6.563011169433594,\n",
       "  1952.160888671875,\n",
       "  2.4275052547454834,\n",
       "  1862.4671630859375,\n",
       "  0.45501065254211426,\n",
       "  23.1572265625,\n",
       "  4.468562126159668],\n",
       " [555.9090576171875,\n",
       "  0.752328097820282,\n",
       "  552.1017456054688,\n",
       "  0.09669935703277588,\n",
       "  509.2764892578125,\n",
       "  0.3955080509185791,\n",
       "  510.39105224609375,\n",
       "  0.6253772377967834,\n",
       "  23.57958984375,\n",
       "  5.648453235626221,\n",
       "  1805.6595458984375,\n",
       "  2.0466904640197754,\n",
       "  1638.9161376953125,\n",
       "  0.4416099786758423,\n",
       "  23.27490234375,\n",
       "  4.707568168640137],\n",
       " [461.33685302734375,\n",
       "  0.5373710989952087,\n",
       "  460.9328308105469,\n",
       "  0.061272501945495605,\n",
       "  495.4185791015625,\n",
       "  0.397222101688385,\n",
       "  493.66632080078125,\n",
       "  0.5336120128631592,\n",
       "  23.525390625,\n",
       "  4.3111371994018555,\n",
       "  1977.481201171875,\n",
       "  2.1406033039093018,\n",
       "  1835.2607421875,\n",
       "  0.45607149600982666,\n",
       "  23.3076171875,\n",
       "  4.324819087982178],\n",
       " [533.39599609375,\n",
       "  0.656173050403595,\n",
       "  533.3324584960938,\n",
       "  0.08971589803695679,\n",
       "  522.6936645507812,\n",
       "  0.38623571395874023,\n",
       "  517.7694702148438,\n",
       "  0.4715064764022827,\n",
       "  23.55810546875,\n",
       "  4.226595401763916,\n",
       "  2169.544921875,\n",
       "  2.2290446758270264,\n",
       "  2033.7691650390625,\n",
       "  0.5122239589691162,\n",
       "  23.361328125,\n",
       "  3.8083722591400146],\n",
       " [559.7035522460938,\n",
       "  0.7281148433685303,\n",
       "  551.8671875,\n",
       "  0.11720460653305054,\n",
       "  519.9166259765625,\n",
       "  0.3642628788948059,\n",
       "  518.7129516601562,\n",
       "  0.4220329523086548,\n",
       "  23.4443359375,\n",
       "  4.670986652374268,\n",
       "  2222.1435546875,\n",
       "  2.247276782989502,\n",
       "  2074.75244140625,\n",
       "  0.5098394155502319,\n",
       "  23.78662109375,\n",
       "  3.4825634956359863],\n",
       " [567.2763061523438,\n",
       "  0.7441552877426147,\n",
       "  561.5234985351562,\n",
       "  0.11823737621307373,\n",
       "  528.0216064453125,\n",
       "  0.34214723110198975,\n",
       "  524.8822631835938,\n",
       "  0.39714741706848145,\n",
       "  23.533203125,\n",
       "  4.050064563751221,\n",
       "  2240.959228515625,\n",
       "  2.2694990634918213,\n",
       "  2093.698974609375,\n",
       "  0.487917423248291,\n",
       "  23.423828125,\n",
       "  3.719846725463867],\n",
       " [568.357177734375,\n",
       "  0.7227872014045715,\n",
       "  561.73876953125,\n",
       "  0.10999637842178345,\n",
       "  520.8630981445312,\n",
       "  0.3461345434188843,\n",
       "  521.6428833007812,\n",
       "  0.4032065272331238,\n",
       "  23.39599609375,\n",
       "  3.585258960723877,\n",
       "  2256.71435546875,\n",
       "  2.3182919025421143,\n",
       "  2072.732421875,\n",
       "  0.5017269849777222,\n",
       "  23.62890625,\n",
       "  3.340902090072632],\n",
       " [575.7058715820312,\n",
       "  0.7645131349563599,\n",
       "  569.7431640625,\n",
       "  0.11758255958557129,\n",
       "  524.3619995117188,\n",
       "  0.33959895372390747,\n",
       "  519.729248046875,\n",
       "  0.3852890729904175,\n",
       "  23.42724609375,\n",
       "  3.3970141410827637,\n",
       "  2261.47314453125,\n",
       "  2.2747082710266113,\n",
       "  2058.16455078125,\n",
       "  0.5338283777236938,\n",
       "  23.55810546875,\n",
       "  3.2305033206939697],\n",
       " [575.8563232421875,\n",
       "  0.6272275447845459,\n",
       "  572.400634765625,\n",
       "  0.11960476636886597,\n",
       "  517.6373901367188,\n",
       "  0.3399832248687744,\n",
       "  515.148681640625,\n",
       "  0.4228227138519287,\n",
       "  23.60107421875,\n",
       "  3.190110921859741,\n",
       "  2270.972900390625,\n",
       "  2.280024528503418,\n",
       "  2011.479248046875,\n",
       "  0.5144652128219604,\n",
       "  23.47802734375,\n",
       "  3.5301284790039062],\n",
       " [578.8635864257812,\n",
       "  0.6383201479911804,\n",
       "  576.9562377929688,\n",
       "  0.12475991249084473,\n",
       "  521.5350952148438,\n",
       "  0.3435882329940796,\n",
       "  520.0801391601562,\n",
       "  0.4072108268737793,\n",
       "  23.56591796875,\n",
       "  3.286276340484619,\n",
       "  2263.336669921875,\n",
       "  2.3348753452301025,\n",
       "  2008.62939453125,\n",
       "  0.5019239783287048,\n",
       "  23.3828125,\n",
       "  3.5930094718933105],\n",
       " [581.1464233398438,\n",
       "  0.5741882920265198,\n",
       "  577.8228759765625,\n",
       "  0.1255386471748352,\n",
       "  518.3360595703125,\n",
       "  0.33077675104141235,\n",
       "  519.647216796875,\n",
       "  0.4355928897857666,\n",
       "  23.65087890625,\n",
       "  2.886080741882324,\n",
       "  2267.958251953125,\n",
       "  2.2480990886688232,\n",
       "  1995.921630859375,\n",
       "  0.5542809963226318,\n",
       "  23.3330078125,\n",
       "  3.360177755355835],\n",
       " [584.4497680664062,\n",
       "  0.6294931769371033,\n",
       "  578.4276123046875,\n",
       "  0.13371813297271729,\n",
       "  528.8734741210938,\n",
       "  0.3218846917152405,\n",
       "  526.7945556640625,\n",
       "  0.4569775462150574,\n",
       "  23.6572265625,\n",
       "  3.0856692790985107,\n",
       "  2266.20654296875,\n",
       "  2.182969570159912,\n",
       "  1967.21337890625,\n",
       "  0.4968227744102478,\n",
       "  23.73291015625,\n",
       "  2.718515396118164],\n",
       " [583.6256713867188,\n",
       "  0.6172342896461487,\n",
       "  583.1256103515625,\n",
       "  0.10505765676498413,\n",
       "  529.14501953125,\n",
       "  0.3165642023086548,\n",
       "  526.3787841796875,\n",
       "  0.4082059860229492,\n",
       "  23.58349609375,\n",
       "  2.6454861164093018,\n",
       "  2264.189453125,\n",
       "  2.285841464996338,\n",
       "  1950.939697265625,\n",
       "  0.5878726840019226,\n",
       "  23.6474609375,\n",
       "  2.8140316009521484],\n",
       " [583.8199462890625,\n",
       "  0.6464528441429138,\n",
       "  581.4925537109375,\n",
       "  0.10774552822113037,\n",
       "  523.9591064453125,\n",
       "  0.3358761668205261,\n",
       "  520.75390625,\n",
       "  0.4497884511947632,\n",
       "  23.77685546875,\n",
       "  2.8348569869995117,\n",
       "  2263.622802734375,\n",
       "  2.1877620220184326,\n",
       "  1912.1458740234375,\n",
       "  0.5148097276687622,\n",
       "  23.74267578125,\n",
       "  2.7103543281555176],\n",
       " [588.4365844726562,\n",
       "  0.7102442979812622,\n",
       "  584.5026245117188,\n",
       "  0.08480232954025269,\n",
       "  517.0885009765625,\n",
       "  0.3016759753227234,\n",
       "  511.3031005859375,\n",
       "  0.3805203437805176,\n",
       "  23.98046875,\n",
       "  2.502507209777832,\n",
       "  2261.66455078125,\n",
       "  2.322610378265381,\n",
       "  1907.42333984375,\n",
       "  0.5320769548416138,\n",
       "  24.02490234375,\n",
       "  2.9919838905334473],\n",
       " [584.9698486328125,\n",
       "  0.6039909720420837,\n",
       "  584.9385986328125,\n",
       "  0.08101516962051392,\n",
       "  522.7590942382812,\n",
       "  0.32528936862945557,\n",
       "  509.5503845214844,\n",
       "  0.3806809186935425,\n",
       "  23.99853515625,\n",
       "  2.4124844074249268,\n",
       "  2266.2685546875,\n",
       "  2.2436776161193848,\n",
       "  1900.979736328125,\n",
       "  0.5404404997825623,\n",
       "  23.93115234375,\n",
       "  3.1508889198303223],\n",
       " [583.977783203125,\n",
       "  0.6110658049583435,\n",
       "  580.5493774414062,\n",
       "  0.07297354936599731,\n",
       "  525.9127807617188,\n",
       "  0.3524985909461975,\n",
       "  518.247802734375,\n",
       "  0.39116334915161133,\n",
       "  23.65185546875,\n",
       "  3.309617042541504,\n",
       "  2256.93505859375,\n",
       "  2.3186914920806885,\n",
       "  1920.048583984375,\n",
       "  0.49788832664489746,\n",
       "  23.78759765625,\n",
       "  2.9941306114196777],\n",
       " [582.6812133789062,\n",
       "  0.6244142055511475,\n",
       "  579.0165405273438,\n",
       "  0.06836694478988647,\n",
       "  528.1910400390625,\n",
       "  0.3511504530906677,\n",
       "  521.6552734375,\n",
       "  0.3845393657684326,\n",
       "  23.66552734375,\n",
       "  3.390458822250366,\n",
       "  2266.36572265625,\n",
       "  2.3848490715026855,\n",
       "  1946.039306640625,\n",
       "  0.4725618362426758,\n",
       "  23.681640625,\n",
       "  3.2359561920166016],\n",
       " [589.0439453125,\n",
       "  0.647401750087738,\n",
       "  580.0185546875,\n",
       "  0.08478641510009766,\n",
       "  530.8030395507812,\n",
       "  0.36401045322418213,\n",
       "  518.1044921875,\n",
       "  0.41440534591674805,\n",
       "  23.7470703125,\n",
       "  3.1453001499176025,\n",
       "  2278.91455078125,\n",
       "  2.3692164421081543,\n",
       "  2004.4193115234375,\n",
       "  0.4465763568878174,\n",
       "  23.9638671875,\n",
       "  2.8182740211486816],\n",
       " [579.189697265625,\n",
       "  0.5818643569946289,\n",
       "  578.2363891601562,\n",
       "  0.0782923698425293,\n",
       "  526.4498901367188,\n",
       "  0.36496788263320923,\n",
       "  520.1578369140625,\n",
       "  0.4389892816543579,\n",
       "  24.02294921875,\n",
       "  2.8884236812591553,\n",
       "  2317.220947265625,\n",
       "  2.4707884788513184,\n",
       "  2070.95166015625,\n",
       "  0.4539518356323242,\n",
       "  24.1015625,\n",
       "  2.9239501953125],\n",
       " [577.7275390625,\n",
       "  0.6642389893531799,\n",
       "  572.911376953125,\n",
       "  0.0636407732963562,\n",
       "  522.5046997070312,\n",
       "  0.38246989250183105,\n",
       "  518.6887817382812,\n",
       "  0.4926132559776306,\n",
       "  24.34033203125,\n",
       "  2.938244581222534,\n",
       "  2279.50927734375,\n",
       "  2.3699731826782227,\n",
       "  2068.78564453125,\n",
       "  0.442621648311615,\n",
       "  23.93115234375,\n",
       "  3.1408629417419434],\n",
       " [581.6062622070312,\n",
       "  0.7548089623451233,\n",
       "  576.9749755859375,\n",
       "  0.07341468334197998,\n",
       "  527.8392944335938,\n",
       "  0.43817317485809326,\n",
       "  517.4796142578125,\n",
       "  0.5391720533370972,\n",
       "  23.81689453125,\n",
       "  4.471227169036865,\n",
       "  2254.224609375,\n",
       "  2.490445137023926,\n",
       "  2084.81298828125,\n",
       "  0.5005207061767578,\n",
       "  23.51123046875,\n",
       "  3.7103781700134277],\n",
       " [585.5465698242188,\n",
       "  0.7748951315879822,\n",
       "  576.2280883789062,\n",
       "  0.19862014055252075,\n",
       "  508.59149169921875,\n",
       "  0.4854831099510193,\n",
       "  500.3270263671875,\n",
       "  0.6727812886238098,\n",
       "  23.73388671875,\n",
       "  3.2316932678222656,\n",
       "  2227.103271484375,\n",
       "  2.2988553047180176,\n",
       "  2080.45166015625,\n",
       "  0.4891366958618164,\n",
       "  22.62158203125,\n",
       "  5.379321575164795],\n",
       " [559.2716064453125,\n",
       "  0.7842873334884644,\n",
       "  558.2542724609375,\n",
       "  0.05534720420837402,\n",
       "  505.0348205566406,\n",
       "  0.5201359987258911,\n",
       "  489.2934265136719,\n",
       "  0.749696671962738,\n",
       "  22.32373046875,\n",
       "  5.5425333976745605,\n",
       "  2414.10009765625,\n",
       "  2.3478844165802,\n",
       "  2269.348876953125,\n",
       "  0.5463172793388367,\n",
       "  24.74169921875,\n",
       "  2.4871199131011963]]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fft_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5683,  0.6894,  0.2632,  0.8460],\n",
       "        [ 0.2312,  0.9403,  0.6002, -0.3943],\n",
       "        [ 0.8212, -0.8066, -0.2923, -0.1997]], requires_grad=True)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.retain_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/new_home/zhuocheng/.conda/envs/gzhch/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fidx = torch.tensor([0, 2], dtype=torch.long)\n",
    "uidx = torch.tensor([1, 3, 4, 5], dtype=torch.long)\n",
    "fixed = torch.rand([2,], requires_grad=False)\n",
    "upd = torch.rand([4,], requires_grad=True)\n",
    "z = torch.empty([6,])\n",
    "z[fidx] = fixed \n",
    "z[uidx] = upd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand([2,], requires_grad=True).requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0935, 0.3170, 0.5559, 0.0571, 0.3765, 0.9540],\n",
       "       grad_fn=<IndexPutBackward>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3170, 0.0571, 0.3765, 0.9540], requires_grad=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0045, -0.0172, -0.0128,  ..., -0.0050,  0.0072, -0.0141],\n",
       "        [-0.0238, -0.0002,  0.0267,  ...,  0.0393,  0.0430, -0.0210],\n",
       "        [-0.0289, -0.0530, -0.0137,  ..., -0.0343,  0.0066,  0.0190],\n",
       "        ...,\n",
       "        [-0.0704, -0.0226, -0.0191,  ..., -0.0182,  0.0135,  0.1044],\n",
       "        [ 0.0148,  0.0049, -0.0193,  ..., -0.0014, -0.0083,  0.0438],\n",
       "        [-0.0076, -0.0642,  0.0450,  ...,  0.0460,  0.0176, -0.0481]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = torch.rand([8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed = torch.rand([8,8], requires_grad=False)\n",
    "upd = torch.rand([8,8,], requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3098, 0.1129, 0.1221, 0.2449, 0.8691, 0.9782, 0.1611, 0.4430],\n",
       "        [0.8113, 0.8244, 0.4457, 0.7023, 0.6530, 0.0697, 0.4740, 0.0369],\n",
       "        [0.4168, 0.6675, 0.8303, 0.7439, 0.3991, 0.8096, 0.7633, 0.4938],\n",
       "        [0.4399, 0.7600, 0.9685, 0.5660, 0.9933, 0.8289, 0.7115, 0.1037],\n",
       "        [0.5361, 0.4298, 0.1905, 0.3586, 0.5448, 0.1012, 0.9732, 0.4701],\n",
       "        [0.3495, 0.6514, 0.7202, 0.2389, 0.5106, 0.2862, 0.4585, 0.9733],\n",
       "        [0.5668, 0.2888, 0.3527, 0.3397, 0.9852, 0.4811, 0.5537, 0.3705],\n",
       "        [0.7946, 0.4163, 0.9332, 0.7965, 0.3650, 0.2812, 0.9269, 0.1901]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3098, 0.1129, 0.1221, 0.3601, 0.8691, 0.2005, 0.0959, 0.8767],\n",
       "        [0.8113, 0.8244, 0.4457, 0.1861, 0.6530, 0.1461, 0.3547, 0.6297],\n",
       "        [0.4168, 0.6675, 0.8303, 0.1479, 0.3991, 0.7895, 0.3370, 0.7067],\n",
       "        [0.4399, 0.7600, 0.9685, 0.3722, 0.9933, 0.5936, 0.9328, 0.6431],\n",
       "        [0.5361, 0.4298, 0.1905, 0.9693, 0.5448, 0.2846, 0.2737, 0.6361],\n",
       "        [0.3495, 0.6514, 0.7202, 0.9887, 0.5106, 0.8071, 0.1498, 0.9463],\n",
       "        [0.5668, 0.2888, 0.3527, 0.3169, 0.9852, 0.8933, 0.1465, 0.4002],\n",
       "        [0.7946, 0.4163, 0.9332, 0.8618, 0.3650, 0.9348, 0.6085, 0.5080]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed*(flag < 0.5) + upd*(flag >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " = torch.load('../transformer/models/roberta.large/model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
